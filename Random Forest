#Random Forest model: Using CTG(Heart rate data) we build Random forest model.

data <- read.csv("C:/Users/naveenjv/Desktop/itas/CTG.csv", header = TRUE, sep = ",", stringsAsFactors = FALSE)

View(data)
str(data)
data$NSP <- as.factor(data$NSP)
str(data)
table(data$NSP)

#data partition

set.seed(123)
ind <- sample(2, nrow(data) , replace = TRUE, prob = c(0.7,0.3))

train <- data[ind==1,]
test <- data[ind==2,]
  
#Load the Libraries to build the random Forest model.

install.packages("randomForest")
library(randomForest)
set.seed(222)

# Use RandomForest function to build a model.

rf <- randomForest(NSP ~ ., data = train)
print(rf)
 
attributes(rf)

rf$mtry

#prediction and confusion matrix - train data
library(caret)

p1 <- predict(rf, data = train)
head(p1)

head(train$NSP)

confusionMatrix(p1, train$NSP)

#prediction and confusion matrix - TEST data

p2 <- predict(rf, test)

head(p2)
head(test$NSP)
table(test$NSP)

confusionMatrix(p2, test$NSP)

#Error rate of RandomForest

plot(rf)

#Tune Random Forest (Tune mtry)

tuneRF(train[,-22], train[,22], 
       stepFactor = 0.5, 
       plot = TRUE,
       ntreeTry = 300,
       trace = TRUE,
       improve = 0.05)   #as the OOB error reaches bottom at mtry = 8 and the plot remains constant at trees = 300, so change the model data).

rf1 <- randomForest(NSP ~ ., data = train, ntree = 300, mtry = 8, importance = TRUE, proximity = TRUE)
print(rf1)

#prediction and confusion matrix - train data
library(caret)

p3 <- predict(rf1, data = train)
head(p1)

head(train$NSP)

confusionMatrix(p3, train$NSP)

#prediction and confusion matrix - TEST data

p4 <- predict(rf1, test)

confusionMatrix(p4, test$NSP)

#No of Nodes for the trees

hist(treesize(rf),
     main = "NO OF NODES IN THE TREES",
     col = "green")
#variable importance 

varImpPlot(rf,
           sort = TRUE,
           n.var = 10,
           main = "top 10 var")
importance(rf)  # quantitative importance varibles 

varUsed(rf) # how often the var is used in the model.

#partial dependence plot

partialPlot(rf, train, ASTV, class = "1") #it tells which varibales at which position are more imp in the class

# Extract Single tree

getTree(rf, 1, labelVar = TRUE) #GETTING INFO FROM TREE 1(TERMINAL NODES = -1 STATUS = CLASS)

#Multi Dimensional scaling plot proximity matrix.

MDSplot(rf, train$NSP)
  
